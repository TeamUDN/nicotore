<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>顔認識</title>
<style>
  /* video 要素の上に canvas 要素をオーバーレイするための CSS */
  #container {              /* コンテナ用の div について */
    position: relative;     /* 座標指定を相対値指定にする */
  }
  #video {                  /* カメラ映像を流す video について */
    transform: scaleX(-1);  /* 左右反転させる */
  }
  #canvas {                 /* 描画用の canvas について */
    transform: scaleX(-1);  /* 左右反転させる */
    position: absolute;     /* 座標指定を絶対値指定にして */
    left: 0;                /* X座標を0に */
    top: 0;                 /* Y座標を0に */
  }
</style>
</head>

<body>
  <!-- video の上に canvas をオーバーレイするための div 要素 -->
  <div id="container">
    <!-- カメラ映像を流す video -->
    <video id="video" width="400" height="300" autoplay></video>
    <!-- 重ねて描画する canvas -->
    <canvas id="canvas" width="400" height="300"></canvas>
  </div>

  <!-- データ表示用 div 要素 -->
  <div id="dat"></div>

  <!-- clmtrackr 関連ファイルの読み込み -->
  <script src="../static/js/face/clmtrackr.js"></script>  <!-- clmtrackr のメインライブラリの読み込み -->
  <script src="../static/js/face/model_pca_20_svm.js"></script>   <!-- 顔モデル（※）の読み込み -->

<script>
  var video = document.getElementById("video");
  var canvas = document.getElementById("canvas");
  var context = canvas.getContext("2d");

  // getUserMedia によるカメラ映像の取得
  // メディアデバイスを取得
  var media = navigator.mediaDevices.getUserMedia({
    // カメラの映像を使う（スマホならインカメラ）
    video: {facingMode: "user"},
    // マイクの音声は使わない
    audio: false
  });

  // メディアデバイスが取得できたら
  media.then((stream) => {
    // video 要素にストリームを渡す
    video.srcObject = stream;
  });

  // clmtrackr の開始
  // tracker オブジェクトを作成
  var tracker = new clm.tracker();
  // tracker を所定のフェイスモデル（※）で初期化
  tracker.init(pModel);
  // video 要素内でフェイストラッキング開始
  tracker.start(video);

  // 描画ループ
  function drawLoop() {
    // drawLoop 関数を繰り返し実行
    requestAnimationFrame(drawLoop);
    // 顔部品の現在位置の取得
    var positions = tracker.getCurrentPosition();
    // データの表示
    showData(positions);
    // canvas をクリア
    context.clearRect(0, 0, canvas.width, canvas.height);
    // canvas にトラッキング結果を描画
    tracker.draw(canvas);
  }
  // drawLoop関数の初回実行
  drawLoop();

  // 顔部品（特徴点）の位置データを表示する showData 関数
  function showData(pos) {
    //test
    console.log('右口角の座標');
    console.log('x座標：「'+pos[44][0]+'」y座標：「' + pos[44][1] + '」');
    console.log('左口角の座標');
    console.log('x座標：「' + pos[50][0] + '」y座標：「' + pos[50][1] + '」');
    console.log('2点の差');
    console.log('x座標：「' + Math.round(pos[50][0] - pos[44][0]) + '」y座標：「' + Math.round(pos[50][1] - pos[44][1] )+ '」');

    // データの文字列を入れる変数
    var str = "";
    // 全ての特徴点（71個）について
    for(var i = 0; i < pos.length; i++) {
      str += "特徴点" + i + ": ("
        // X座標（四捨五入して整数に）
        + Math.round(pos[i][0]) + ", "
        // Y座標（四捨五入して整数に）
        + Math.round(pos[i][1]) + ")<br>";
    }
    // データ表示用div要素の取得
    var dat = document.getElementById("dat");
    // データ文字列の表示
    dat.innerHTML = str;
  }
</script>
</body>
</html>
